{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"/home/chi/Data_challenge/Mask_RCNN/\")\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn.model import log\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "# Local path to trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "# Download COCO trained weights from Releases if needed\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    utils.download_trained_weights(COCO_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104069 images founded for training\n",
      "88486 images founded for testing\n",
      "Out of 104069 training images, only 29070 images that has ships\n"
     ]
    }
   ],
   "source": [
    "PATH = '../input'\n",
    "TRAIN = '../input/train/'\n",
    "TEST = '../input/test/'\n",
    "SEGMENTATION = '../input/train_ship_segmentations.csv'\n",
    "PRETRAINED = '../input/fine-tuning-resnet34-on-ship-detection/models/Resnet34_lable_256_1.h5'\n",
    "exclude_list = ['6384c3e78.jpg','13703f040.jpg', '14715c06d.jpg',  '33e0ff2d5.jpg',\n",
    "                '4d4e09f2a.jpg', '877691df8.jpg', '8b909bb20.jpg', 'a8d99130e.jpg', \n",
    "                'ad55c3143.jpg', 'c8260c541.jpg', 'd6c7f17c7.jpg', 'dc3e7c901.jpg',\n",
    "                'e44dffe88.jpg', 'ef87bad36.jpg', 'f083256d8.jpg'] #corrupted images\n",
    "\n",
    "train_names = [f for f in os.listdir(TRAIN)]\n",
    "test_names = [f for f in os.listdir(TEST)]\n",
    "for el in exclude_list:\n",
    "    if(el in train_names): train_names.remove(el)\n",
    "    if(el in test_names): test_names.remove(el)\n",
    "print(f'{len(train_names)} images founded for training')\n",
    "print(f'{len(test_names)} images founded for testing')\n",
    "\n",
    "img_df = pd.read_csv(os.path.join(PATH, SEGMENTATION))\n",
    "\n",
    "img_df.drop(img_df[img_df['ImageId']=='6384c3e78.jpg'].index,inplace = True)\n",
    "img_df['ships'] = img_df['EncodedPixels'].map(lambda c_row: 1 if isinstance(c_row, str) else 0)\n",
    "\n",
    "\n",
    "\n",
    "img_ship = img_df.groupby('ImageId', group_keys=False).agg({'ships': 'sum'})\n",
    "print(f'Out of {len(train_names)} training images, only {len(img_ship.drop(img_ship.ships[img_ship.ships==0].index))} images that has ships')\n",
    "\n",
    "ships_only = img_ship.drop(img_ship.ships[img_ship.ships==0].index) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_rle_encode(img, **kwargs):\n",
    "    '''\n",
    "    Encode connected regions as separated masks\n",
    "    '''\n",
    "    labels = label(img)\n",
    "    if img.ndim > 2:\n",
    "        return [rle_encode(np.sum(labels==k, axis=2), **kwargs) for k in np.unique(labels[labels>0])]\n",
    "    else:\n",
    "        return [rle_encode(labels==k, **kwargs) for k in np.unique(labels[labels>0])]\n",
    "\n",
    "# ref: https://www.kaggle.com/paulorzp/run-length-encode-and-decode\n",
    "def rle_encode(img, min_max_threshold=1e-3, max_mean_threshold=None):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    if np.max(img) < min_max_threshold:\n",
    "        return '' ## no need to encode if it's all zeros\n",
    "    if max_mean_threshold and np.mean(img) > max_mean_threshold:\n",
    "        return '' ## ignore overfilled mask\n",
    "    pixels = img.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def rle_decode(mask_rle, shape=(768, 768)):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (height,width) of array to return \n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "    '''\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape).T  # Needed to align to RLE direction\n",
    "\n",
    "def masks_as_image(in_mask_list):\n",
    "    # Take the individual ship masks and create a single mask array for all ships\n",
    "    all_masks = np.zeros((768, 768), dtype = np.uint8)\n",
    "    for mask in in_mask_list:\n",
    "        if isinstance(mask, str):\n",
    "            all_masks |= rle_decode(mask)\n",
    "    return all_masks\n",
    "\n",
    "def masks_as_color(in_mask_list):\n",
    "    # Take the individual ship masks and create a color mask array for each ships\n",
    "    all_masks = np.zeros((768, 768), dtype = np.float)\n",
    "    scale = lambda x: (len(in_mask_list)+x+1) / (len(in_mask_list)*2) ## scale the heatmap image to shift \n",
    "    for i,mask in enumerate(in_mask_list):\n",
    "        if isinstance(mask, str):\n",
    "            all_masks[:,:] += scale(i) * rle_decode(mask)\n",
    "    return all_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AirbusDataset(utils.Dataset):\n",
    "\n",
    "    def load_train(self, idx, sz):\n",
    "        \"\"\"Generate the requested number of synthetic images.\n",
    "        count: number of images to generate.\n",
    "        sz: the size of the generated images.\n",
    "        \"\"\"\n",
    "        # Add classes\n",
    "        # source = Airbus\n",
    "        # class = ship\n",
    "        self.add_class(\"Airbus\", 1, \"ship\")\n",
    "\n",
    "        # Add images\n",
    "        for i in idx:\n",
    "            imagename = ships_only.index[i]\n",
    "\n",
    "            self.add_image(\"Airbus\", image_id=i, fname=imagename, path=TRAIN, sz=sz)\n",
    "            \n",
    "#     def load_val(self, count, sz):\n",
    "#         \"\"\"Generate the requested number of synthetic images.\n",
    "#         count: number of images to generate.\n",
    "#         sz: the size of the generated images.\n",
    "#         \"\"\"\n",
    "#         # Add classes\n",
    "#         # source = Airbus\n",
    "#         # class = ship\n",
    "#         self.add_class(\"Airbus\", 1, \"ship\")\n",
    "\n",
    "#         # Add images\n",
    "#         for i in range(count):\n",
    "#             imagename = ships_only.index[i+20000]\n",
    "#             self.add_image(\"Airbus\", image_id=i+500, fname=imagename, path=TRAIN, sz=sz)\n",
    "\n",
    "    def load_image(self, image_id):\n",
    "        \"\"\"Generate an image from the specs of the given image ID.\n",
    "        \"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        img = plt.imread(info['path']+info['fname'])\n",
    "        if info['sz'] == 768: return img \n",
    "        else: return cv2.resize(img, (info['sz'], info['sz']))\n",
    "    \n",
    "    def load_mask(self, image_id):\n",
    "        \"\"\"Load instance masks for the given image.\n",
    "        Returns:\n",
    "            masks: A bool array of shape [height, width, instance count] with\n",
    "                a binary mask per instance.\n",
    "            class_ids: a 1D array of class IDs of the instance masks.\n",
    "        \"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        rle = img_df.loc[img_df['ImageId']==info['fname'],'EncodedPixels'].values\n",
    "        mask = np.empty([info['sz'], info['sz'], len(rle)])\n",
    "        class_ids = np.ones(len(rle))\n",
    "\n",
    "        for i,rle_ in enumerate(rle):\n",
    "            mask_ = rle_decode(rle_)\n",
    "            if info['sz'] != 768: mask_ = cv2.resize(mask_, (info['sz'], info['sz']))\n",
    "            mask[:,:,i] = mask_\n",
    "\n",
    "        return mask.astype(np.bool), class_ids.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# all_idx = list(np.arange(len(ships_only)))\n",
    "# train_idx, val_idx = train_test_split(all_idx, test_size=0.2, shuffle=True)\n",
    "\n",
    "import pickle\n",
    "# with open('idx.pickle', 'wb') as f:\n",
    "#     pickle.dump([train_idx, val_idx], f)\n",
    "\n",
    "\n",
    "with open('idx.pickle', 'rb') as f:\n",
    "    train_idx, val_idx = pickle.load(f)\n",
    "\n",
    "    \n",
    "sz = 128\n",
    "bs = 8\n",
    "\n",
    "# Training dataset \n",
    "dataset_train = AirbusDataset()\n",
    "dataset_train.load_train(train_idx, sz)\n",
    "dataset_train.prepare()\n",
    "\n",
    "# Validation dataset\n",
    "dataset_val = AirbusDataset()\n",
    "dataset_val.load_train(val_idx, sz)\n",
    "dataset_val.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShipsConfig(Config):\n",
    "    \"\"\"Configuration for training on the nucleus segmentation dataset.\"\"\"\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"ships\"\n",
    "\n",
    "    # Adjust depending on your GPU memory\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 6\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + 1  # Background + nucleus\n",
    "\n",
    "    # Number of training and validation steps per epoch\n",
    "    STEPS_PER_EPOCH = 1000\n",
    "    VALIDATION_STEPS = 200\n",
    "\n",
    "    # Don't exclude based on confidence. Since we have two classes\n",
    "    # then 0.5 is the minimum anyway as it picks between nucleus and BG\n",
    "    DETECTION_MIN_CONFIDENCE = 0\n",
    "\n",
    "    # Input image resizing\n",
    "    # Random crops of size 512x512\n",
    "    IMAGE_RESIZE_MODE = \"square\"\n",
    "    IMAGE_MIN_DIM = sz\n",
    "    IMAGE_MAX_DIM = sz\n",
    "\n",
    "    # Length of square anchor side in pixels\n",
    "    RPN_ANCHOR_SCALES = (4, 8, 16, 32, 64)\n",
    "\n",
    "    # ROIs kept after non-maximum supression (training and inference)\n",
    "    POST_NMS_ROIS_TRAINING = 1000\n",
    "    POST_NMS_ROIS_INFERENCE = 2000\n",
    "\n",
    "    # Non-max suppression threshold to filter RPN proposals.\n",
    "    # You can increase this during training to generate more propsals.\n",
    "    RPN_NMS_THRESHOLD = 0.9\n",
    "\n",
    "    # How many anchors per image to use for RPN training\n",
    "    RPN_TRAIN_ANCHORS_PER_IMAGE = 128\n",
    "\n",
    "    # Image mean (RGB)\n",
    "    MEAN_PIXEL = np.array([56.37015, 80.04626, 85.10948])\n",
    "\n",
    "    # If enabled, resizes instance masks to a smaller size to reduce\n",
    "    # memory load. Recommended when using high-resolution images.\n",
    "    USE_MINI_MASK = True\n",
    "    MINI_MASK_SHAPE = (56, 56)  # (height, width) of the mini-mask\n",
    "\n",
    "    # Number of ROIs per image to feed to classifier/mask heads\n",
    "    # The Mask RCNN paper uses 512 but often the RPN doesn't generate\n",
    "    # enough positive proposals to fill this and keep a positive:negative\n",
    "    # ratio of 1:3. You can increase the number of proposals by adjusting\n",
    "    # the RPN NMS threshold.\n",
    "    TRAIN_ROIS_PER_IMAGE = 128\n",
    "\n",
    "    # Maximum number of ground truth instances to use in one image\n",
    "    MAX_GT_INSTANCES = 200\n",
    "\n",
    "    # Max number of final detections per image\n",
    "    DETECTION_MAX_INSTANCES = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ShipsConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ceate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model in training mode\n",
    "# Create model in training mode\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
    "                          model_dir=MODEL_DIR)\n",
    "\n",
    "model_path = os.path.join('/home/chi/Data_challenge/Airbus Ship Detection/code/weights', \"airbus.h5\")\n",
    "\n",
    "init_with = \"coco\"  # imagenet, coco, or last\n",
    "\n",
    "if init_with == \"imagenet\":\n",
    "    model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
    "elif init_with == \"coco\":\n",
    "    model.load_weights(COCO_MODEL_PATH, by_name=True,exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "elif init_with == 'saved':\n",
    "    model.load_weights(model_path, by_name=True)\n",
    "elif init_with == \"last\":\n",
    "    # Load the last model you trained and continue training\n",
    "    model.load_weights(model.find_last(), by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training - Stage 1\n",
    "print(\"Training network heads\")\n",
    "model.train(dataset_train, dataset_val,\n",
    "            learning_rate=config.LEARNING_RATE,\n",
    "            epochs=10,\n",
    "            layers='heads')\n",
    "\n",
    "# Training - Stage 2\n",
    "# Finetune layers from ResNet stage 4 and up\n",
    "print(\"Fine tune Resnet stage 4 and up\")\n",
    "model.train(dataset_train, dataset_val,\n",
    "            learning_rate=config.LEARNING_RATE,\n",
    "            epochs=30,\n",
    "            layers='4+')\n",
    "\n",
    "# Training - Stage 3\n",
    "# Fine tune all layers\n",
    "print(\"Fine tune all layers\")\n",
    "model.train(dataset_train, dataset_val,\n",
    "            learning_rate=config.LEARNING_RATE / 10,\n",
    "            epochs=50,\n",
    "            layers='all')\n",
    "\n",
    "\n",
    "model.keras_model.save_weights(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ax(rows=1, cols=1, size=8):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Change the default size attribute to control the size\n",
    "    of rendered images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceConfig(ShapesConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "inference_config = InferenceConfig()\n",
    "\n",
    "# Recreate the model in inference mode\n",
    "model = modellib.MaskRCNN(mode=\"inference\", \n",
    "                          config=inference_config,\n",
    "                          model_dir=MODEL_DIR)\n",
    "\n",
    "init_with = \"saved\"  # imagenet, coco, or last\n",
    "print(\"Loading weights from \", init_with)\n",
    "if init_with == \"saved\":\n",
    "    model.load_weights(model_path, by_name=True)\n",
    "elif init_with == \"last\":\n",
    "    # Load the last model you trained and continue training\n",
    "    model.load_weights(model.find_last(), by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on a random image\n",
    "image_id = random.choice(dataset_val.image_ids)\n",
    "original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "    modellib.load_image_gt(dataset_val, inference_config, \n",
    "                           image_id, use_mini_mask=False)\n",
    "\n",
    "log(\"original_image\", original_image)\n",
    "log(\"image_meta\", image_meta)\n",
    "log(\"gt_class_id\", gt_class_id)\n",
    "log(\"gt_bbox\", gt_bbox)\n",
    "log(\"gt_mask\", gt_mask)\n",
    "\n",
    "visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
    "                            dataset_train.class_names, figsize=(8, 8))\n",
    "\n",
    "results = model.detect([original_image], verbose=1)\n",
    "\n",
    "r = results[0]\n",
    "visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
    "                            dataset_val.class_names, r['scores'], ax=get_ax())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
