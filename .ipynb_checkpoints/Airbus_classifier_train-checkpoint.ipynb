{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.imports import *\n",
    "from fastai.conv_learner import *\n",
    "from fastai.dataset import *\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../input'\n",
    "TRAIN = '../input/train/'\n",
    "TEST = '../input/test/'\n",
    "SEGMENTATION = '../input/train_ship_segmentations.csv'\n",
    "PRETRAINED = '../input/fine-tuning-resnet34-on-ship-detection/models/Resnet34_lable_256_1.h5'\n",
    "exclude_list = ['6384c3e78.jpg','13703f040.jpg', '14715c06d.jpg',  '33e0ff2d5.jpg',\n",
    "                '4d4e09f2a.jpg', '877691df8.jpg', '8b909bb20.jpg', 'a8d99130e.jpg', \n",
    "                'ad55c3143.jpg', 'c8260c541.jpg', 'd6c7f17c7.jpg', 'dc3e7c901.jpg',\n",
    "                'e44dffe88.jpg', 'ef87bad36.jpg', 'f083256d8.jpg'] #corrupted images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104069 images founded for training\n",
      "88486 images founded for testing\n",
      "Out of 104069 training images, only 29070 images that has ships\n"
     ]
    }
   ],
   "source": [
    "train_names = [f for f in os.listdir(TRAIN)]\n",
    "test_names = [f for f in os.listdir(TEST)]\n",
    "for el in exclude_list:\n",
    "    if(el in train_names): train_names.remove(el)\n",
    "    if(el in test_names): test_names.remove(el)\n",
    "print(f'{len(train_names)} images founded for training')\n",
    "print(f'{len(test_names)} images founded for testing')\n",
    "\n",
    "img_df = pd.read_csv(os.path.join(PATH, SEGMENTATION))\n",
    "\n",
    "img_df.drop(img_df[img_df['ImageId']=='6384c3e78.jpg'].index,inplace = True)\n",
    "img_df['ships'] = img_df['EncodedPixels'].map(lambda c_row: 1 if isinstance(c_row, str) else 0)\n",
    "\n",
    "img_ship = img_df.groupby('ImageId').agg({'ships': 'sum'})\n",
    "print(f'Out of {len(train_names)} training images, only {len(img_ship.drop(img_ship.ships[img_ship.ships==0].index))} images that has ships')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a label for all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_label = pd.DataFrame()\n",
    "img_label['has_ships'] = img_ship['ships'].apply(lambda x: 0 if x == 0 else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Down sample from no ships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLES_PER_GROUP = len(img_ship.drop(img_ship.ships[img_ship.ships==0].index))\n",
    "balanced_img_label = img_label.groupby('has_ships', group_keys=False).apply(lambda x: x.sample(SAMPLES_PER_GROUP) if len(x) > SAMPLES_PER_GROUP else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand0(s): return random.random()*(s*2)-s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomRotate(CoordTransform):\n",
    "    \"\"\" Rotates images and (optionally) target y.\n",
    "    Rotating coordinates is treated differently for x and y on this\n",
    "    transform.\n",
    "     Arguments:\n",
    "        deg (float): degree to rotate.\n",
    "        p (float): probability of rotation\n",
    "        mode: type of border\n",
    "        tfm_y (TfmType): type of y transform\n",
    "    \"\"\"\n",
    "    def __init__(self, deg, p=0.75, mode=cv2.BORDER_REFLECT, tfm_y=TfmType.NO):\n",
    "        super().__init__(tfm_y)\n",
    "        self.deg,self.p = deg,p\n",
    "        if tfm_y == TfmType.COORD or tfm_y == TfmType.CLASS:\n",
    "            self.modes = (mode,cv2.BORDER_CONSTANT)\n",
    "        else:\n",
    "            self.modes = (mode,mode)\n",
    "\n",
    "    def set_state(self):\n",
    "        self.store.rdeg = rand0(self.deg)\n",
    "        self.store.rp = random.random()<self.p\n",
    "\n",
    "    def do_transform(self, x, is_y):\n",
    "        if self.store.rp: \n",
    "            rotated = rotate_bound2(x, self.store.rdeg) \n",
    "        else: \n",
    "            rotated = x\n",
    "        return cv2.resize(rotated, x.shape[:2], interpolation=cv2.INTER_AREA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_bound2(image, angle, mode=cv2.BORDER_DEFAULT, interpolation=cv2.INTER_AREA):\n",
    "    # grab the dimensions of the image and then determine the\n",
    "    # center\n",
    "    (h, w) = image.shape[:2]\n",
    "    (cX, cY) = (w / 2, h / 2)\n",
    "\n",
    "    # grab the rotation matrix (applying the negative of the\n",
    "    # angle to rotate clockwise), then grab the sine and cosine\n",
    "    # (i.e., the rotation components of the matrix)\n",
    "    M = cv2.getRotationMatrix2D((cX, cY), -angle, 1.0)\n",
    "    cos = np.abs(M[0, 0])\n",
    "    sin = np.abs(M[0, 1])\n",
    "\n",
    "    # compute the new bounding dimensions of the image\n",
    "    nW = int((h * sin) + (w * cos))\n",
    "    nH = int((h * cos) + (w * sin))\n",
    "\n",
    "    # adjust the rotation matrix to take into account translation\n",
    "    M[0, 2] += (nW / 2) - cX\n",
    "    M[1, 2] += (nH / 2) - cY\n",
    "\n",
    "    # perform the actual rotation and return the image\n",
    "    return cv2.warpAffine(image, M, (nW, nH), borderMode=mode, flags=cv2.WARP_FILL_OUTLIERS+interpolation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_img_label.to_csv(f'{PATH}/labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(sz, bs): # sz: image size, bs: batch size\n",
    "    aug_tfms = [RandomRotate(180),RandomDihedral(),RandomLighting(0.05, 0.05),RandomStretch(max_stretch=1.05),\n",
    "                Cutout(n_holes=10, length=0.02*sz)]\n",
    "    tfms = tfms_from_model(arch, sz, aug_tfms=aug_tfms)\n",
    "    data = ImageClassifierData.from_csv(PATH, 'train', f'{PATH}/labels.csv',tfms=tfms, bs=bs)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch=resnext50\n",
    "sz = 128\n",
    "bs = 64\n",
    "data = get_data(sz, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chi/anaconda3/lib/python3.6/site-packages/fastai/initializers.py:6: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  if hasattr(m, 'weight'): init_fn(m.weight)\n",
      "/home/chi/anaconda3/lib/python3.6/site-packages/fastai/initializers.py:6: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  if hasattr(m, 'weight'): init_fn(m.weight)\n"
     ]
    }
   ],
   "source": [
    "learn = ConvLearner.pretrained(arch, data, precompute=True, ps=0.5)\n",
    "\n",
    "lr = 1e-2\n",
    "learn.fit(lr, 2)\n",
    "\n",
    "learn.precompute=False\n",
    "learn.fit(lr, 3, cycle_len=1)\n",
    "\n",
    "learn.save('c128run')\n",
    "learn.load('c128run')\n",
    "\n",
    "learn.unfreeze()\n",
    "lrs=np.array([lr/9,lr/3,lr])\n",
    "learn.fit(lrs, 3, cycle_len=1)\n",
    "\n",
    "learn.save('c128run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put on cluster \n",
    "# change size \n",
    "# change batch size\n",
    "# train more epocs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
