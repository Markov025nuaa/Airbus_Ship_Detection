{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.conv_learner import *\n",
    "from fastai.dataset import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './'\n",
    "TRAIN = '../input/train/'\n",
    "TEST = '../input/test/'\n",
    "SEGMENTATION = '../input/train_ship_segmentations.csv'\n",
    "PRETRAINED = '../input/fine-tuning-resnet34-on-ship-detection/models/Resnet34_lable_256_1.h5'\n",
    "exclude_list = ['6384c3e78.jpg','13703f040.jpg', '14715c06d.jpg',  '33e0ff2d5.jpg',\n",
    "                '4d4e09f2a.jpg', '877691df8.jpg', '8b909bb20.jpg', 'a8d99130e.jpg', \n",
    "                'ad55c3143.jpg', 'c8260c541.jpg', 'd6c7f17c7.jpg', 'dc3e7c901.jpg',\n",
    "                'e44dffe88.jpg', 'ef87bad36.jpg', 'f083256d8.jpg'] #corrupted images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nw = 2   #number of workers for data loader\n",
    "arch = resnet34 #specify target architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_names = [f for f in os.listdir(TRAIN)]\n",
    "test_names = [f for f in os.listdir(TEST)]\n",
    "for el in exclude_list:\n",
    "    if(el in train_names): train_names.remove(el)\n",
    "    if(el in test_names): test_names.remove(el)\n",
    "#5% of data in the validation set is sufficient for model evaluation\n",
    "tr_n, val_n = train_test_split(train_names, test_size=0.2, random_state=42)\n",
    "segmentation_df = pd.read_csv(os.path.join(PATH, SEGMENTATION)).set_index('ImageId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_empty(names):\n",
    "    return [name for name in names \n",
    "            if(type(segmentation_df.loc[name]['EncodedPixels']) != float)]\n",
    "\n",
    "tr_n = cut_empty(tr_n)\n",
    "val_n = cut_empty(val_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask(img_id, df):\n",
    "    shape = (768,768)\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    masks = df.loc[img_id]['EncodedPixels']\n",
    "    if(type(masks) == float): return img.reshape(shape)\n",
    "    if(type(masks) == str): masks = [masks]\n",
    "    for mask in masks:\n",
    "        s = mask.split()\n",
    "        for i in range(len(s)//2):\n",
    "            start = int(s[2*i]) - 1\n",
    "            length = int(s[2*i+1])\n",
    "            img[start:start+length] = 1\n",
    "    return img.reshape(shape).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pdFilesDataset(FilesDataset):\n",
    "    def __init__(self, fnames, path, transform):\n",
    "        self.segmentation_df = pd.read_csv(SEGMENTATION).set_index('ImageId')\n",
    "        super().__init__(fnames, transform, path)\n",
    "    \n",
    "    def get_x(self, i):\n",
    "        img = open_image(os.path.join(self.path, self.fnames[i]))\n",
    "        if self.sz == 768: return img \n",
    "        else: return cv2.resize(img, (self.sz, self.sz))\n",
    "    \n",
    "    def get_y(self, i):\n",
    "        mask = np.zeros((768,768), dtype=np.uint8) if (self.path == TEST) \\\n",
    "            else get_mask(self.fnames[i], self.segmentation_df)\n",
    "        img = Image.fromarray(mask).resize((self.sz, self.sz)).convert('RGB')\n",
    "        return np.array(img).astype(np.float32)\n",
    "    \n",
    "    def get_c(self): return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(sz,bs):\n",
    "    #data augmentation\n",
    "    aug_tfms = [RandomRotate(20, tfm_y=TfmType.CLASS),\n",
    "                RandomDihedral(tfm_y=TfmType.CLASS),\n",
    "                RandomLighting(0.05, 0.05, tfm_y=TfmType.CLASS)]\n",
    "    tfms = tfms_from_model(arch, sz, crop_type=CropType.NO, tfm_y=TfmType.CLASS, \n",
    "                aug_tfms=aug_tfms)\n",
    "    tr_names = tr_n if (len(tr_n)%bs == 0) else tr_n[:-(len(tr_n)%bs)] #cut incomplete batch\n",
    "    ds = ImageData.get_ds(pdFilesDataset, (tr_names,TRAIN), (val_n,TRAIN), tfms, test=(test_names,TEST))\n",
    "    md = ImageData(PATH, ds, bs, num_workers=nw, classes=None)\n",
    "    #md.is_multi = False\n",
    "    return md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut,lr_cut = model_meta[arch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base():                   #load ResNet34 model\n",
    "    layers = cut_model(arch(True), cut)\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "def load_pretrained(model, path): #load a model pretrained on ship/no-ship classification\n",
    "    weights = torch.load(PRETRAINED, map_location=lambda storage, loc: storage)\n",
    "    model.load_state_dict(weights, strict=False)\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnetBlock(nn.Module):\n",
    "    def __init__(self, up_in, x_in, n_out):\n",
    "        super().__init__()\n",
    "        up_out = x_out = n_out//2\n",
    "        self.x_conv  = nn.Conv2d(x_in,  x_out,  1)\n",
    "        self.tr_conv = nn.ConvTranspose2d(up_in, up_out, 2, stride=2)\n",
    "        self.bn = nn.BatchNorm2d(n_out)\n",
    "        \n",
    "    def forward(self, up_p, x_p):\n",
    "        up_p = self.tr_conv(up_p)\n",
    "        x_p = self.x_conv(x_p)\n",
    "        cat_p = torch.cat([up_p,x_p], dim=1)\n",
    "        return self.bn(F.relu(cat_p))\n",
    "\n",
    "class SaveFeatures():\n",
    "    features=None\n",
    "    def __init__(self, m): self.hook = m.register_forward_hook(self.hook_fn)\n",
    "    def hook_fn(self, module, input, output): self.features = output\n",
    "    def remove(self): self.hook.remove()\n",
    "    \n",
    "class Unet34(nn.Module):\n",
    "    def __init__(self, rn):\n",
    "        super().__init__()\n",
    "        self.rn = rn\n",
    "        self.sfs = [SaveFeatures(rn[i]) for i in [2,4,5,6]]\n",
    "        self.up1 = UnetBlock(512,256,256)\n",
    "        self.up2 = UnetBlock(256,128,256)\n",
    "        self.up3 = UnetBlock(256,64,256)\n",
    "        self.up4 = UnetBlock(256,64,256)\n",
    "        self.up5 = nn.ConvTranspose2d(256, 1, 2, stride=2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.rn(x))\n",
    "        x = self.up1(x, self.sfs[3].features)\n",
    "        x = self.up2(x, self.sfs[2].features)\n",
    "        x = self.up3(x, self.sfs[1].features)\n",
    "        x = self.up4(x, self.sfs[0].features)\n",
    "        x = self.up5(x)\n",
    "        return x[:,0]\n",
    "    \n",
    "    def close(self):\n",
    "        for sf in self.sfs: sf.remove()\n",
    "            \n",
    "class UnetModel():\n",
    "    def __init__(self,model,name='Unet'):\n",
    "        self.model,self.name = model,name\n",
    "\n",
    "    def get_layer_groups(self, precompute):\n",
    "        lgs = list(split_by_idxs(children(self.model.rn), [lr_cut]))\n",
    "        return lgs + [children(self.model)[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(input, target):\n",
    "    input = torch.sigmoid(input)\n",
    "    smooth = 1.0\n",
    "\n",
    "    iflat = input.view(-1)\n",
    "    tflat = target.view(-1)\n",
    "    intersection = (iflat * tflat).sum()\n",
    "    \n",
    "    return ((2.0 * intersection + smooth) / (iflat.sum() + tflat.sum() + smooth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        \n",
    "    def forward(self, input, target):\n",
    "        if not (target.size() == input.size()):\n",
    "            raise ValueError(\"Target size ({}) must be the same as input size ({})\"\n",
    "                             .format(target.size(), input.size()))\n",
    "\n",
    "        max_val = (-input).clamp(min=0)\n",
    "        loss = input - input * target + max_val + \\\n",
    "            ((-max_val).exp() + (-input - max_val).exp()).log()\n",
    "\n",
    "        invprobs = F.logsigmoid(-input * (target * 2.0 - 1.0))\n",
    "        loss = (invprobs * self.gamma).exp() * loss\n",
    "        \n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixedLoss(nn.Module):\n",
    "    def __init__(self, alpha, gamma):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.focal = FocalLoss(gamma)\n",
    "        \n",
    "    def forward(self, input, target):\n",
    "        loss = self.alpha*self.focal(input, target) - torch.log(dice_loss(input, target))\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice(pred, targs):\n",
    "    pred = (pred>0).float()\n",
    "    return 2.0 * (pred*targs).sum() / ((pred+targs).sum() + 1.0)\n",
    "\n",
    "def IoU(pred, targs):\n",
    "    pred = (pred>0).float()\n",
    "    intersection = (pred*targs).sum()\n",
    "    return intersection / ((pred+targs).sum() - intersection + 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m_base = load_pretrained(get_base(),PRETRAINED)\n",
    "m_base = get_base()\n",
    "m = to_gpu(Unet34(m_base))\n",
    "models = UnetModel(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = 128 #image size\n",
    "bs = 8  #batch size\n",
    "\n",
    "md = get_data(sz,bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = ConvLearner(md, models)\n",
    "learn.opt_fn=optim.Adam\n",
    "learn.crit = MixedLoss(10.0, 2.0)\n",
    "learn.metrics=[accuracy_thresh(0.5),dice,IoU]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze_to(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.lr_find()\n",
    "# learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wd=1e-7\n",
    "# lr = 4e-3\n",
    "# learn.fit(lr,1, wds=wd, cycle_len=4,use_clr=(20,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn.save('128urn-tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('128urn-tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.bn_freeze(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 4e-3\n",
    "wd=1e-7\n",
    "lrs = np.array([lr/100,lr/10,lr])/2\n",
    "#learn.fit(lrs, 1, wds=wd, cycle_len=10,use_clr=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn.save('128urn-0')\n",
    "learn.load('128urn-0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 256x256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sz = 256 #image size\n",
    "bs = 4  #batch size\n",
    "\n",
    "md = get_data(sz,bs)\n",
    "learn.set_data(md)\n",
    "learn.unfreeze()\n",
    "learn.bn_freeze(True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IoU(pred, targs):\n",
    "    pred = (pred > 0.5).astype(float)\n",
    "    intersection = (pred*targs).sum()\n",
    "    return intersection / ((pred+targs).sum() - intersection + 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(pred, true):\n",
    "    n_th = 10\n",
    "    b = 4\n",
    "    thresholds = [0.5 + 0.05*i for i in range(n_th)]\n",
    "    n_masks = len(true)\n",
    "    n_pred = len(pred)\n",
    "    ious = []\n",
    "    score = 0\n",
    "    for mask in true:\n",
    "        buf = []\n",
    "        for p in pred: buf.append(IoU(p,mask))\n",
    "        ious.append(buf)\n",
    "    for t in thresholds:   \n",
    "        tp, fp, fn = 0, 0, 0\n",
    "        for i in range(n_masks):\n",
    "            match = False\n",
    "            for j in range(n_pred):\n",
    "                if ious[i][j] > t: match = True\n",
    "            if not match: fn += 1\n",
    "        \n",
    "        for j in range(n_pred):\n",
    "            match = False\n",
    "            for i in range(n_masks):\n",
    "                if ious[i][j] > t: match = True\n",
    "            if match: tp += 1\n",
    "            else: fp += 1\n",
    "        score += ((b+1)*tp)/((b+1)*tp + b*fn + fp)       \n",
    "    return score/n_th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_mask(mask):\n",
    "    threshold = 0.5\n",
    "    threshold_obj = 30 #ignor predictions composed of \"threshold_obj\" pixels or less\n",
    "    labled,n_objs = ndimage.label(mask > threshold)\n",
    "    result = []\n",
    "    for i in range(n_objs):\n",
    "        obj = (labled == i + 1).astype(int)\n",
    "        if(obj.sum() > threshold_obj): result.append(obj)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask_ind(img_id, df, shape = (768,768)): #return mask for each ship\n",
    "    masks = df.loc[img_id]['EncodedPixels']\n",
    "    if(type(masks) == float): return []\n",
    "    if(type(masks) == str): masks = [masks]\n",
    "    result = []\n",
    "    for mask in masks:\n",
    "        img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "        s = mask.split()\n",
    "        for i in range(len(s)//2):\n",
    "            start = int(s[2*i]) - 1\n",
    "            length = int(s[2*i+1])\n",
    "            img[start:start+length] = 1\n",
    "        result.append(img.reshape(shape).T)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Score_eval():\n",
    "    def __init__(self):\n",
    "        self.segmentation_df = pd.read_csv(SEGMENTATION).set_index('ImageId')\n",
    "        self.score, self.count = 0.0, 0\n",
    "        \n",
    "    def put(self,pred,name):\n",
    "        true = get_mask_ind(name, self.segmentation_df)\n",
    "        self.score += get_score(pred,true)\n",
    "        self.count += 1\n",
    "        \n",
    "    def evaluate(self):\n",
    "        return self.score/self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = to_gpu(Unet34(get_base()))\n",
    "models = UnetModel(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = 768 #image size\n",
    "bs = 8  #batch size\n",
    "md = get_data(sz,bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = ConvLearner(md, models)\n",
    "learn.models_path = PRETRAINED_SEGMENTATION_PATH\n",
    "learn.load('256tmp')\n",
    "learn.models_path = PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pred(learner, dl, F_save): #if use train dl, disable shuffling\n",
    "    learner.model.eval();\n",
    "    name_list = dl.dataset.fnames\n",
    "    num_batchs = len(dl)\n",
    "    t = tqdm(iter(dl), leave=False, total=num_batchs)\n",
    "    count = 0\n",
    "    for x,y in t:\n",
    "        py = to_np(F.sigmoid(learn.model(V(x))))\n",
    "        batch_size = len(py)\n",
    "        for i in range(batch_size):\n",
    "            F_save(py[i],to_np(y[i]),name_list[count])\n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = Score_eval()\n",
    "process_pred = lambda yp, y, name : score.put(split_mask(yp),name)\n",
    "model_pred(learn, md.val_dl, process_pred)\n",
    "print('\\n',score.evaluate())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
